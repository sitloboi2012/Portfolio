from __future__ import annotations

import os
import streamlit as st

from bot_object.llama2 import Llama_Bot
from bot_object.gpt import GPT_Model


def check_validate_bot(bot_type: str):
    if bot_type in ["Llama 2 ðŸ¦™", "GPT4All Wizard 1.1 ðŸ”¥"]:
        return bot_type, None

    elif bot_type == "GPT-3.5-Turbo-16k ðŸ¤–":
        openai_api_key = st.sidebar.text_input("Enter your OpenAI API Key: ")

        if (openai_api_key != "") and (openai_api_key.startswith("sk-")):
            st.success("Accepted OpenAI API Key")
            return bot_type, openai_api_key

    else:
        return None, None


def generate_material():
    temperature = st.sidebar.slider(
        "Choose the temperature:", min_value=0.01, max_value=5.0, value=0.1, step=0.01
    )
    top_p = st.sidebar.slider(
        "Choose the top_p value:", min_value=0.01, max_value=1.0, value=0.9, step=0.01
    )
    max_length = st.sidebar.slider(
        "Choose the max_length:", min_value=64, max_value=4096, value=512, step=8
    )
    clear = st.sidebar.button("Clear Chat History", on_click=clear_chat_history)

    return temperature, top_p, max_length, clear


def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "How may I assist you today?"}
    ]


def main() -> None:
    st.set_page_config(page_title="Multi Chatbot Project ðŸ¦™ðŸ’¬")

    st.sidebar.title("Welcome to UniverseBot")
    bot_type, api_key = check_validate_bot(
        st.sidebar.selectbox(
            "Choose your bot:",
            [
                "Choose bot at here",
                "Llama 2 ðŸ¦™",
                "GPT-3.5-Turbo-16k ðŸ¤–",
                "GPT4All Wizard 1.1 ðŸ”¥",
            ],
        )
    )
    if bot_type != None:
        temperature, top_p, max_length, clear = generate_material()
    else:
        st.title("UniverseBot ðŸ¦™ðŸ¤–ðŸ”¥")
        st.write(
            "This is a page where you can find a collection of different Generative AI model"
        )
        st.info("How To Use")
        st.markdown(
            """
                    1. Choose the type of the bot
                    2. Choose the range of parameter you want to use
                    3. Start using it
                    """
        )

    if bot_type == "Llama 2 ðŸ¦™":
        os.environ["REPLICATE_API_TOKEN"] = "r8_AOdyXko1qgGpcM6urUaWG1iL9ohZUYD0jF6Bx"
        model_obj = Llama_Bot("7B", temperature, top_p, max_length)
        model_obj.__repr__()
    elif bot_type == "GPT-3.5-Turbo-16k ðŸ¤–":
        os.environ["OPENAI_API_KEY"] = api_key
        model_obj = GPT_Model(temperature)

    if bot_type:
        if "messages" not in st.session_state.keys():
            st.session_state.messages = [
                {"role": "assistant", "content": "How may I assist you today?"}
            ]

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])

        if prompt := st.chat_input():
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)

        if st.session_state.messages[-1]["role"] != "assistant":
            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    response = model_obj.generate_response(
                        prompt, st.session_state.messages
                    )
                    placeholder = st.empty()
                    full_response = ""
                    for item in response:
                        full_response += item
                        placeholder.markdown(full_response)
                    placeholder.markdown(full_response)
            message = {"role": "assistant", "content": full_response}
            st.session_state.messages.append(message)


if __name__ == "__main__":
    main()
